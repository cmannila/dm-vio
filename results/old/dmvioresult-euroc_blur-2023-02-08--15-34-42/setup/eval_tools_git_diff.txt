diff --git a/configs.yaml b/configs.yaml
index 87fa7f2..c26007d 100644
--- a/configs.yaml
+++ b/configs.yaml
@@ -1,3 +1,19 @@
+workpc:
+  short_name: workpc
+  dmvio_folder: /home/cm2113/workspace/dm-vio
+  pc_config_path:
+  pc_config_command: apt list
+  slurm: false
+  results_path: /home/cm2113/workspace/dm-vio/results
+  euroc:
+    dataset_path: /home/cm2113/workspace/Datasets/euroc
+    results_path: /home/cm2113/workspace/dm-vio/results
+  euroc_blur:
+    dataset_path: /home/cm2113/workspace/Datasets/euroc
+    results_path: /home/cm2113/workspace/dm-vio/results
+  tumvi:
+    dataset_path: /home/cm2113/workspace/Datasets/tumvi
+    results_path: /home/cm2113/workspace/dm-vio/results
 example_config:
   short_name: example
   dmvio_folder: /path/to/dmvio
@@ -11,8 +27,8 @@ example_config:
   slurm: false # Can be set to true for running on Slurm servers.
   results_path: /path/where/results/are/stored # Your results will be stored (and read from) here.
   euroc: # Paths to the individual datasets.
-    dataset_path: /path/to/euroc/dataset
-    results_path: /path/where/results/are/stored
+    dataset_path: /home/cm2113/workspace/Datasets/euroc
+    results_path: /home/cm2113/workspace/dm-vio/results
   tumvi:
     dataset_path: /path/to/tumvi/dataset
     results_path: /path/where/results/are/stored
@@ -37,6 +53,19 @@ config_general: # This is where configuration shared for all machines is stored
     # improves the robustness of the method to bad visual initialization.
     start_times: [950, 800, 410, 445, 460, 22, 115, 250, 26, 100, 115]
     end_times: [3600, 3000, 2600, 1925, 2200, 2800, 1600, 2020, 2130, 2230, 1880]
+  euroc_blur: # With start times as used by DSO and VI-DSO.
+    afterpath: mav0/cam0/
+    afterpath2: mav0/cam1/
+    res_prefix: mav_
+    dataset_args: files=./data calib=./camera.txt mode=1
+    default_iter: 10
+    folder_names: [MH_01_easy_blur_1-1-1-1, V2_03_difficult_blur_1-1-1-1] #, MH_02_easy, MH_03_medium, MH_04_difficult, MH_05_difficult, V1_01_easy, V1_02_medium, V1_03_difficult, V2_01_easy, V2_02_medium, V2_03_difficult
+    # We use the start times proposed in the DSO paper, which were also taken over in VI-DSO.
+    # When starting from the beginning, the method works also well, but then the setting
+    # --dmvio_args="init_ba_skipFirstKFs=1 init_requestFullResetNormalizedErrorThreshold=0.8" should be used, which
+    # improves the robustness of the method to bad visual initialization.
+    start_times: [950,115] # , 800, 410, 445, 460, 22, 115, 250, 26, 100, 115 
+    end_times: [3600,1880] # , 3000, 2600, 1925, 2200, 2800, 1600, 2020, 2130, 2230, 1880
   tumvi:
     afterpath: dso/cam0/
     afterpath2: dso/cam1/
diff --git a/run_dmvio.py b/run_dmvio.py
index 856bc38..b38354d 100644
--- a/run_dmvio.py
+++ b/run_dmvio.py
@@ -335,4 +335,4 @@ def build_results_name(name, realtime, dataset):
 
 
 if __name__ == "__main__":
-    main()
+    main()
\ No newline at end of file
diff --git a/trajectory_evaluation/evaluate.py b/trajectory_evaluation/evaluate.py
index f5b8782..3c9c4d5 100644
--- a/trajectory_evaluation/evaluate.py
+++ b/trajectory_evaluation/evaluate.py
@@ -114,11 +114,10 @@ def evaluate_with_config(pair, always_reevaluate=False):
     return evaluate_run(folder, dataset, setup['num_iter'], None, always_reevaluate)
 
 
-def evaluate_run(run_folder: Path, dataset: Dataset, num_iter: int, name=None, always_reevaluate=False) -> (
-        EvalResults, EvalResults):
+def evaluate_run(run_folder: Path, dataset: Dataset, num_iter: int, name=None, always_reevaluate=False) -> (EvalResults, EvalResults):
     """Evaluate all sequences and iterations of a run and save it to file (and return it).
     If the evaluation result has already been saved to file it will just load it.
-        returns
+        retu
 
     :param run_folder: Folder of the run which will be evaluated.
     :param dataset: Dataset to evaluate on.
